# name                 : Generate Description From OpenAI
# script-type          : Python
# description          : Exports diagrams of the selected Element
# popup                : enableFor(org.polarsys.capella.core.data.capellacore.CapellaElement)

# Include necessary Capella Modeller API
include('workspace://Python4Capella/simplified_api/capella.py')
if False:
    from simplified_api.capella import *

# Include requirement API
include('workspace://Python4Capella/simplified_api/requirement.py')
if False:
    from simplified_api.requirement import *

# Include utilities
include('workspace://Python4Capella/utilities/CapellaPlatform.py')
if False:
    from utilities.CapellaPlatform import *

import openai
import os
import eclipse.system.ui as ui  # @UnresolvedImport
from py4j.java_gateway import java_import

jvm = gateway.jvm  # @UndefinedVariable
java_import(jvm, 'org.polarsys.capella.core.model.handler.helpers.CapellaAdapterHelper')
CapellaAdapterHelper = jvm.org.polarsys.capella.core.model.handler.helpers.CapellaAdapterHelper

# Set OpenAI API Key (Ensure you have a valid key)
client = openai.OpenAI(api_key="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")  # Correct way to instantiate with API key


# Use the correct model name
openaimodel = "gpt-3.5-turbo"

if __name__ == '__main__':
    # From Eclipse, get the active Part's selection
    selected = ui.getSelection()
    print("Test")

    # Resolve the Part's selection to Capella semantic elements
    selected_objs = CapellaAdapterHelper.resolveSemanticObjects(selected.toList(), True)

    for selected_obj in selected_objs:
        prompt = f"Write a description for {selected_obj.getName()}, cite references, and format as HTML."
        print("Prompt:", prompt)

        try:
            response = client.chat.completions.create(
                model=openaimodel,
                messages=[{"role": "user", "content": prompt}],  # Corrected parameter
                temperature=0.7,
                max_tokens=256,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )

            ai_response = response.choices[0].message.content  # Corrected response parsing
            print("Response:", ai_response)

            res = Sirius.get_session(selected_obj).getSessionResource().getURI().toPlatformString(True)
            model_path = "/" + res[1:res.rfind(".")] + ".aird"

            print("Model path:", model_path)
            model = CapellaModel()
            model.open(model_path)

            model.start_transaction()
            try:
                selected_obj.setDescription(f"<p>Generated by OpenAI model {openaimodel}</p>{ai_response}")
            except Exception as e:
                model.rollback_transaction()
                print("Error:", e)
                raise
            else:
                model.commit_transaction()
                print("Model Committed")

            # Save the Capella model
            model.save()

        except openai.OpenAIError as e:
            print(f"OpenAI API Error: {e}")
